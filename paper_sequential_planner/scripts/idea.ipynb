{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f709c88f",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Voronoi](#toc1_)    \n",
    "  - [Voronoi 2d](#toc1_1_)    \n",
    "  - [Voronoi 6d](#toc1_2_)    \n",
    "- [Gaussian PDF 1d](#toc2_)    \n",
    "- [Guassian PDF function 2d](#toc3_)    \n",
    "- [Guassian GMM 1d](#toc4_)    \n",
    "- [Guassian GMM 1d with Unknow K cluster](#toc5_)    \n",
    "- [Guassian GMM 2D](#toc6_)    \n",
    "- [Sorting Sampling](#toc7_)    \n",
    "- [Cspace Learning Path Prediction](#toc8_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d57c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, ConvexHull, Delaunay\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from shapely.geometry import Polygon as shapelyPolygon\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import os\n",
    "import time\n",
    "\n",
    "np.set_printoptions(linewidth=1000, suppress=True, precision=2)\n",
    "np.random.seed(42)\n",
    "rsrc = os.environ[\"RSRC_DIR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783fd1f6",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Voronoi](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca53e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrn2d_grid():\n",
    "    x = np.linspace(0, 1, 10)\n",
    "    y = np.linspace(0, 1, 10)\n",
    "    points = np.meshgrid(x, y)\n",
    "    points = np.array([points[0].ravel(), points[1].ravel()]).T\n",
    "    vor = Voronoi(points)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    voronoi_plot_2d(vor, ax)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# vrn2d_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ffa2f",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Voronoi 2d](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fd0faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrn2d_random():\n",
    "    points = np.random.uniform(0, 1, (10, 2))\n",
    "    vor = Voronoi(points)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    voronoi_plot_2d(vor, ax)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# vrn2d_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503c898",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Voronoi 6d](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc2f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vrn6d_random():\n",
    "    rng = np.random.default_rng()\n",
    "    points = rng.random((1000, 6))  # 10 s to make\n",
    "    # points = rng.random((5000, 6))  # 106.54 s to make\n",
    "    # points = rng.random((10000, 6))  # 255 s to make\n",
    "\n",
    "    t0 = time.time()\n",
    "    vor = Voronoi(points)\n",
    "    t1 = time.time()\n",
    "    print(f\"Elapsed time: {t1 - t0:.2f} s\")\n",
    "\n",
    "\n",
    "# vrn6d_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb07578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __test_voronoi():\n",
    "    rng = np.random.default_rng(9)\n",
    "    points = rng.random((10, 2))\n",
    "    print(f\"> points: {points}\")\n",
    "\n",
    "    vor = Voronoi(points)\n",
    "    print(f\"> vor: {vor}\")\n",
    "    print(f\"> vor.points: {vor.points}\")\n",
    "    print(f\"> vor.vertices: {vor.vertices}\")\n",
    "    print(f\"> vor.regions: {vor.regions}\")\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # voronoi_plot_2d(vor, ax)\n",
    "    # for i, p in enumerate(points):\n",
    "    #     ax.text(p[0], p[1], f\"p:{i}:{p}\")\n",
    "    # for i, v in enumerate(vor.vertices):\n",
    "    #     ax.text(v[0], v[1], f\"v:{i}:{v}\")\n",
    "    # for k, r in enumerate(vor.regions):\n",
    "    #     if len(r) == 0:\n",
    "    #         continue\n",
    "    #     if -1 in r:\n",
    "    #         continue\n",
    "    #     vv = [vor.vertices[j] for j in r]\n",
    "    #     vv = np.concatenate(vv)\n",
    "    #     poly = Polygon([vor.vertices[j] for j in r], facecolor=\"none\", edgecolor=\"r\")\n",
    "    #     ax.add_patch(poly)\n",
    "\n",
    "    # ax.set_xlim(0, 1)\n",
    "    # ax.set_ylim(0, 1)\n",
    "    # ax.set_aspect(\"equal\")\n",
    "    # plt.show()\n",
    "\n",
    "    p1 = shapelyPolygon(vor.vertices[vor.regions[4]])\n",
    "    p2 = shapelyPolygon(vor.vertices[vor.regions[6]])\n",
    "    p3 = shapelyPolygon(vor.vertices[vor.regions[7]])\n",
    "\n",
    "    d = p1.distance(p2)\n",
    "    ii = p1.intersection(p2)\n",
    "    id = p1.intersects(p2)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    voronoi_plot_2d(vor, ax)\n",
    "    for i, p in enumerate(points):\n",
    "        ax.text(p[0], p[1], f\"p:{i}:{p}\")\n",
    "    for i, v in enumerate(vor.vertices):\n",
    "        ax.text(v[0], v[1], f\"v:{i}:{v}\")\n",
    "    p11 = Polygon(p1.exterior, facecolor=\"r\", edgecolor=\"r\")\n",
    "    ax.add_patch(p11)\n",
    "    p22 = Polygon(p2.exterior, facecolor=\"b\", edgecolor=\"b\")\n",
    "    ax.add_patch(p22)\n",
    "    p33 = Polygon(p3.exterior, facecolor=\"g\", edgecolor=\"g\")\n",
    "    ax.add_patch(p33)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "    # vorrr = Voronoi(points, incremental=True)\n",
    "    # print(f\"> vorrr: {vorrr}\")\n",
    "    # vorrr.add_points(np.array([[0.5, 0.5]]))\n",
    "\n",
    "    convx1 = ConvexHull(vor.vertices[vor.regions[4]])\n",
    "    print(f\"> convx1: {convx1}\")\n",
    "    eq1 = convx1.equations\n",
    "    print(f\"> eq1: {eq1}\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(convx1.points[:, 0], convx1.points[:, 1], \"o\")\n",
    "    p11 = Polygon(p1.exterior, facecolor=\"r\", edgecolor=\"r\")\n",
    "    ax.add_patch(p11)\n",
    "    for i in range(convx1.points.shape[0]):\n",
    "        ax.axline(\n",
    "            (convx1.points[i, 0], convx1.points[i, 1]),\n",
    "            (\n",
    "                convx1.points[(i + 1) % convx1.points.shape[0], 0],\n",
    "                convx1.points[(i + 1) % convx1.points.shape[0], 1],\n",
    "            ),\n",
    "        )\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# __test_voronoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b942a9a",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Gaussian PDF 1d](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1484d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf_1d():\n",
    "    xm = 0\n",
    "    xstd = 0.3\n",
    "    npoints = 500\n",
    "    xsample = np.random.normal(xm, xstd, (npoints,))\n",
    "    y = 0 * np.arange(npoints)\n",
    "\n",
    "    def normal_pdf(x, mu, sigma):\n",
    "        return (1.0 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(\n",
    "            -0.5 * ((x - mu) / sigma) ** 2\n",
    "        )\n",
    "\n",
    "    def normal_pdf_grad(x, mu, sigma):\n",
    "        f = normal_pdf(x, mu, sigma)\n",
    "        return -(x - mu) / (sigma**2) * f\n",
    "\n",
    "    xpdf = np.linspace(xm - 4 * xstd, xm + 4 * xstd, npoints)\n",
    "    ygussian = normal_pdf(xpdf, xm, xstd)\n",
    "    ypguassian = normal_pdf_grad(xpdf, xm, xstd)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(xsample, y, s=5, c=\"blue\", label=\"Data points\")\n",
    "    ax.plot(xpdf, ygussian, c=\"red\", label=\"Gaussian distribution PDF\")\n",
    "    ax.plot(xpdf, ypguassian, c=\"green\", label=\"Gaussian PDF Gradient\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"X1\")\n",
    "    ax.set_ylabel(\"X2\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim(xm - 4 * xstd, xm + 4 * xstd)\n",
    "    ax.set_ylim(-0.1, 2)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# gaussian_pdf_1d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0568fcc5",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Guassian PDF function 2d](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c34e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf_2d():\n",
    "    mu = np.array([0, 0])  # Mean vector\n",
    "    Sigma = np.array([[0.3, 0.2], [0.2, 0.7]])  # Covariance must positive definite\n",
    "    npoints = 500\n",
    "    xsample = np.random.multivariate_normal(mu, Sigma, npoints)\n",
    "    x1 = np.linspace(\n",
    "        mu[0] - 4 * np.sqrt(Sigma[0, 0]),\n",
    "        mu[0] + 4 * np.sqrt(Sigma[0, 0]),\n",
    "        100,\n",
    "    )\n",
    "    x2 = np.linspace(\n",
    "        mu[1] - 4 * np.sqrt(Sigma[1, 1]),\n",
    "        mu[1] + 4 * np.sqrt(Sigma[1, 1]),\n",
    "        100,\n",
    "    )\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "    pos = np.dstack((X1, X2))\n",
    "\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "    Sigma_det = np.linalg.det(Sigma)\n",
    "    norm_const = 1.0 / (2 * np.pi * np.sqrt(Sigma_det))\n",
    "    diff = pos - mu  # shape (...,2)\n",
    "    exponent = np.einsum(\"...i,ij,...j\", diff, Sigma_inv, diff)  # shape (...,)\n",
    "    Y = norm_const * np.exp(-0.5 * exponent)  # PDF values on grid, shape (...,)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Jacobian (gradient) of Y:  ∇f(x) = - f(x) * Sigma^{-1} (x - mu)\n",
    "    # Vectorized computation:\n",
    "    # ----------------------------\n",
    "    # tmp = Sigma^{-1} @ (x-mu) for each grid point -> shape (...,2)\n",
    "    tmp = np.einsum(\"ij,...j->...i\", Sigma_inv, diff)  # shape (...,2)\n",
    "\n",
    "    # gradient arrays\n",
    "    grad = -Y[..., np.newaxis] * tmp  # shape (...,2)\n",
    "    dY_dx1 = grad[..., 0]\n",
    "    dY_dx2 = grad[..., 1]\n",
    "\n",
    "    x0 = np.array([0.1, -0.05])\n",
    "    f_x0 = norm_const * np.exp(-0.5 * (x0 - mu) @ Sigma_inv @ (x0 - mu))\n",
    "    grad_x0 = -f_x0 * (Sigma_inv @ (x0 - mu))\n",
    "    print(\"f(x0) =\", f_x0)\n",
    "    print(\"grad f(x0) =\", grad_x0)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.scatter(\n",
    "        xsample[:, 0],\n",
    "        xsample[:, 1],\n",
    "        zs=0,\n",
    "        zdir=\"z\",\n",
    "        s=5,\n",
    "        c=\"blue\",\n",
    "        label=\"Data points\",\n",
    "    )\n",
    "    # step = 8\n",
    "    # ax.quiver(\n",
    "    #     X1[::step, ::step],\n",
    "    #     X2[::step, ::step],\n",
    "    #     dY_dx1[::step, ::step],\n",
    "    #     dY_dx2[::step, ::step],\n",
    "    #     scale=50,  # adjust scale for arrow length visibility\n",
    "    #     width=0.003,\n",
    "    #     alpha=0.8,\n",
    "    #     color=\"red\",\n",
    "    #     label=\"Gradient (Jacobian)\",\n",
    "    # )\n",
    "    ax.plot_surface(X1, X2, Y, cmap=\"viridis\", alpha=0.7)\n",
    "    ax.set_xlabel(\"X1\")\n",
    "    ax.set_ylabel(\"X2\")\n",
    "    ax.set_zlabel(\"Probability Density\")\n",
    "    ax.set_title(\"2D Gaussian Distribution PDF\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# gaussian_pdf_2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462da908",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Guassian GMM 1d](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8ea95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_gmm_1d():\n",
    "    # Generate synthetic 1D data\n",
    "    np.random.seed(42)\n",
    "    x = np.concatenate(\n",
    "        [np.random.normal(-2, 0.5, 300), np.random.normal(3, 1.0, 300)]\n",
    "    )\n",
    "    x = x.reshape(-1, 1)\n",
    "\n",
    "    K = 2\n",
    "    gmm = GaussianMixture(n_components=K, covariance_type=\"full\")\n",
    "    gmm.fit(x)\n",
    "\n",
    "    # Extract learned parameters\n",
    "    pi = gmm.weights_  # mixture weights\n",
    "    mu = gmm.means_.flatten()  # means\n",
    "    sigma = np.sqrt(gmm.covariances_.flatten())  # standard deviations\n",
    "\n",
    "    print(\"Mixture weights:\", pi)\n",
    "    print(\"Means:\", mu)\n",
    "    print(\"Sigmas:\", sigma)\n",
    "\n",
    "    def normal_pdf(x, mu, sigma):\n",
    "        return (1.0 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(\n",
    "            -0.5 * ((x - mu) / sigma) ** 2\n",
    "        )\n",
    "\n",
    "    def gmm_pdf(x, pi, mu, sigma):\n",
    "        total = np.zeros_like(x, dtype=float)\n",
    "        for k in range(len(pi)):\n",
    "            total += pi[k] * normal_pdf(x, mu[k], sigma[k])\n",
    "        return total\n",
    "\n",
    "    def gmm_pdf_grad(x, pi, mu, sigma):\n",
    "        # dp/dx = sum_k pi_k * [- (x - mu_k) / sigma_k^2 ] * N(x | mu_k)\n",
    "        grad = np.zeros_like(x, dtype=float)\n",
    "        for k in range(len(pi)):\n",
    "            pdf_k = normal_pdf(x, mu[k], sigma[k])\n",
    "            grad += pi[k] * (-(x - mu[k]) / (sigma[k] ** 2)) * pdf_k\n",
    "        return grad\n",
    "\n",
    "    xgrid = np.linspace(x.min() - 1, x.max() + 1, 500).reshape(-1, 1)\n",
    "    pdf = np.exp(gmm.score_samples(xgrid))  # full mixture PDF\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(x, bins=40, density=True, alpha=0.4, label=\"Data histogram\")\n",
    "    ax.plot(xgrid, pdf, linewidth=2, label=\"GMM PDF curve\")\n",
    "    ax.plot(\n",
    "        xgrid,\n",
    "        gmm_pdf_grad(xgrid, pi, mu, sigma),\n",
    "        linewidth=2,\n",
    "        label=\"GMM PDF Gradient\",\n",
    "    )\n",
    "\n",
    "    # individual components\n",
    "    for k in range(K):\n",
    "        comp_pdf = (\n",
    "            pi[k]\n",
    "            * (1 / np.sqrt(2 * np.pi * sigma[k] ** 2))\n",
    "            * np.exp(-((xgrid - mu[k]) ** 2) / (2 * sigma[k] ** 2))\n",
    "        )\n",
    "        ax.plot(xgrid, comp_pdf, linestyle=\"--\", label=f\"Component {k+1}\")\n",
    "\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# guassian_gmm_1d()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f35288",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[Guassian GMM 1d with Unknow K cluster](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe01cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_gmm_1d_Kunkown():\n",
    "    \"\"\"\n",
    "    Determine the optimal number of Gaussian components in a 1D GMM using AIC/BIC\n",
    "    \"\"\"\n",
    "    random_state = np.random.RandomState(seed=1)\n",
    "\n",
    "    X = np.concatenate(\n",
    "        [\n",
    "            random_state.normal(-1, 1.5, 350),\n",
    "            random_state.normal(0, 1, 500),\n",
    "            random_state.normal(3, 0.5, 150),\n",
    "        ]\n",
    "    ).reshape(-1, 1)\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Learn the best-fit GaussianMixture models\n",
    "    #  Here we'll use scikit-learn's GaussianMixture model. The fit() method\n",
    "    #  uses an Expectation-Maximization approach to find the best\n",
    "    #  mixture of Gaussians for the data\n",
    "\n",
    "    # fit models with 1-10 components find the best number of components using AIC\n",
    "    N = np.arange(1, 11)\n",
    "    models = [None for i in range(len(N))]\n",
    "\n",
    "    for i in range(len(N)):\n",
    "        models[i] = GaussianMixture(N[i]).fit(X)\n",
    "\n",
    "    # compute the AIC and the BIC\n",
    "    AIC = [m.aic(X) for m in models]\n",
    "    BIC = [m.bic(X) for m in models]\n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Plot the results\n",
    "    #  We'll use three panels:\n",
    "    #   1) data + best-fit mixture\n",
    "    #   2) AIC and BIC vs number of components\n",
    "    #   3) probability that a point came from each component\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 1.7))\n",
    "    fig.subplots_adjust(left=0.12, right=0.97, bottom=0.21, top=0.9, wspace=0.5)\n",
    "\n",
    "    # plot 1: data + best-fit mixture\n",
    "    ax = fig.add_subplot(131)\n",
    "    M_best = models[np.argmin(AIC)]\n",
    "\n",
    "    x = np.linspace(-6, 6, 1000)\n",
    "    logprob = M_best.score_samples(x.reshape(-1, 1))\n",
    "    responsibilities = M_best.predict_proba(x.reshape(-1, 1))\n",
    "    pdf = np.exp(logprob)\n",
    "    pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "\n",
    "    ax.hist(X, 30, density=True, histtype=\"stepfilled\", alpha=0.4)\n",
    "    ax.plot(x, pdf, \"-k\")\n",
    "    ax.plot(x, pdf_individual, \"--k\")\n",
    "    ax.text(\n",
    "        0.04, 0.96, \"Best-fit Mixture\", ha=\"left\", va=\"top\", transform=ax.transAxes\n",
    "    )\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(\"$p(x)$\")\n",
    "\n",
    "    # plot 2: AIC and BIC\n",
    "    ax = fig.add_subplot(132)\n",
    "    ax.plot(N, AIC, \"-k\", label=\"AIC\")\n",
    "    ax.plot(N, BIC, \"--k\", label=\"BIC\")\n",
    "    ax.set_xlabel(\"n. components\")\n",
    "    ax.set_ylabel(\"information criterion\")\n",
    "    ax.legend(loc=2)\n",
    "\n",
    "    # plot 3: posterior probabilities for each component\n",
    "    ax = fig.add_subplot(133)\n",
    "\n",
    "    p = responsibilities\n",
    "    p = p[:, (1, 0, 2)]  # rearrange order so the plot looks better\n",
    "    p = p.cumsum(1).T\n",
    "\n",
    "    ax.fill_between(x, 0, p[0], color=\"gray\", alpha=0.3)\n",
    "    ax.fill_between(x, p[0], p[1], color=\"gray\", alpha=0.5)\n",
    "    ax.fill_between(x, p[1], 1, color=\"gray\", alpha=0.7)\n",
    "    ax.set_xlim(-6, 6)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xlabel(\"$x$\")\n",
    "    ax.set_ylabel(r\"$p({\\rm class}|x)$\")\n",
    "\n",
    "    ax.text(-5, 0.3, \"class 1\", rotation=\"vertical\")\n",
    "    ax.text(0, 0.5, \"class 2\", rotation=\"vertical\")\n",
    "    ax.text(3, 0.3, \"class 3\", rotation=\"vertical\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# guassian_gmm_1d_Kunkown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f028b46",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Guassian GMM 2D](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4364bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_gmm_2d():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511faf25",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[GMM Image](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba8928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_2dd_():\n",
    "    n = 500\n",
    "    mean1 = [0, 0]\n",
    "    cov1 = [[1, 0.3], [0.3, 1]]\n",
    "    mean2 = [4, 4]\n",
    "    cov2 = [[1, -0.4], [-0.4, 1.2]]\n",
    "    data1 = np.random.multivariate_normal(mean1, cov1, n)\n",
    "    data2 = np.random.multivariate_normal(mean2, cov2, n)\n",
    "    data = np.vstack([data1, data2])\n",
    "\n",
    "    gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "    gmm.fit(data)\n",
    "\n",
    "    print(\"Gaussian Mixture Model fitted successfully.\")\n",
    "    print(\"Estimated Means:\\n\", gmm.means_)\n",
    "    print(\"\\nEstimated Covariances:\\n\", gmm.covariances_)\n",
    "    print(\"\\nEstimated Component Weights:\\n\", gmm.weights_)\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    print(\"3D plotting modules imported and figure setup for 3D plot.\")\n",
    "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
    "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
    "    x = np.linspace(x_min, x_max, 100)\n",
    "    y = np.linspace(y_min, y_max, 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "\n",
    "    XY = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    # Calculate the log-likelihood of each point on the meshgrid\n",
    "    log_density = gmm.score_samples(XY)\n",
    "    # Convert log-likelihoods to actual probability density function (PDF) values\n",
    "    Z = np.exp(log_density)\n",
    "    Z = Z.reshape(X.shape)\n",
    "\n",
    "    ax.plot_surface(X, Y, Z, cmap=\"viridis\", alpha=0.6)\n",
    "    ax.scatter(\n",
    "        data[:, 0],\n",
    "        data[:, 1],\n",
    "        np.zeros_like(data[:, 0]),\n",
    "        c=\"blue\",\n",
    "        s=10,\n",
    "        label=\"Original Data\",\n",
    "    )\n",
    "    ax.set_xlabel(\"X-axis\")\n",
    "    ax.set_ylabel(\"Y-axis\")\n",
    "    ax.set_zlabel(\"Probability Density\")\n",
    "    ax.set_title(\"3D GMM PDF with Original Data Points\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# gmm_2dd_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ef54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scipy-lectures.org/advanced/image_processing/auto_examples/plot_GMM.html\n",
    "def gmm_image_segmentation():\n",
    "    from scipy import ndimage\n",
    "\n",
    "    n = 10\n",
    "    l = 256\n",
    "    im = np.zeros((l, l))\n",
    "    points = l * np.random.random((2, n**2))\n",
    "    im[(points[0]).astype(np.int32), (points[1]).astype(np.int32)] = 1\n",
    "    im = ndimage.gaussian_filter(im, sigma=l / (4.0 * n))\n",
    "\n",
    "    mask = (im > im.mean()).astype(np.float32)\n",
    "    img = mask + 0.3 * np.random.randn(*mask.shape)\n",
    "\n",
    "    hist, bin_edges = np.histogram(img, bins=60)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "\n",
    "    classif = GaussianMixture(n_components=2)\n",
    "    classif.fit(img.reshape((img.size, 1)))\n",
    "\n",
    "    threshold = np.mean(classif.means_)\n",
    "    binary_img = img > threshold\n",
    "\n",
    "    plt.figure(figsize=(11, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(132)\n",
    "    plt.plot(bin_centers, hist, lw=2)\n",
    "    plt.axvline(0.5, color=\"r\", ls=\"--\", lw=2)\n",
    "    plt.text(0.57, 0.8, \"histogram\", fontsize=20, transform=plt.gca().transAxes)\n",
    "    plt.yticks([])\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(binary_img, cmap=plt.cm.gray, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplots_adjust(\n",
    "        wspace=0.02, hspace=0.3, top=1, bottom=0.1, left=0, right=1\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# gmm_image_segmentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2429232",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Sorting Sampling](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e576da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_sampling_():\n",
    "    xfake = np.linspace(0, 10, 100)\n",
    "    yfake = np.sin(xfake)\n",
    "    Xdata = np.vstack((xfake, yfake)).T\n",
    "    v = np.array([1, 0])\n",
    "\n",
    "    X = np.array(\n",
    "        [\n",
    "            [0.5, 1.5],\n",
    "            [1.0, 0.5],\n",
    "            [1.5, 1.0],\n",
    "            [2.0, 2.5],\n",
    "            [2.5, 1.0],\n",
    "            [3.0, 3.5],\n",
    "            [3.5, 3.0],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    v = np.array([1, 1])\n",
    "    v = v / np.linalg.norm(v)\n",
    "    s = X @ v  # projection scalars\n",
    "    order = np.argsort(s)\n",
    "    X_sorted = X[order]\n",
    "\n",
    "    print(\"Original X:\")\n",
    "    print(X)\n",
    "    print(\"Projection scalars:\")\n",
    "    print(s)\n",
    "    print(\"Sorted order indices:\")\n",
    "    print(order)\n",
    "    print(\"Sorted X:\")\n",
    "    print(X_sorted)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(X[:, 0], X[:, 1], color=\"blue\", label=\"Original Points\")\n",
    "    ax.scatter(X_sorted[:, 0], X_sorted[:, 1], color=\"red\", label=\"Sorted Points\")\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        ax.text(X[i, 0] + 0.1, X[i, 1], f\"{i}\", fontsize=12, color=\"blue\")\n",
    "        ax.text(X_sorted[i, 0], X_sorted[i, 1], f\"{i}\", fontsize=12, color=\"red\")\n",
    "    ax.plot(\n",
    "        [0, v[0] * 6],\n",
    "        [0, v[1] * 6],\n",
    "        color=\"green\",\n",
    "        linestyle=\"--\",\n",
    "        label=\"Projection Direction\",\n",
    "    )\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_aspect(\"equal\", \"box\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# sorting_sampling_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e16f9",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[Cspace Learning Path Prediction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a7345",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(os.path.join(rsrc, \"cspace_dataset.npy\"))\n",
    "N_TRAIN = 1000\n",
    "samples_id = np.random.choice(range(dataset.shape[0]), size=N_TRAIN, replace=False)\n",
    "dataset_samples = dataset[samples_id]\n",
    "X_train = dataset_samples[:, 0:2]\n",
    "y = dataset_samples[:, 2]\n",
    "# y_train = np.where(y <= 0, -1, +1)  # switch sign\n",
    "y_train = np.where(y <= 0, +1, -1)  # switch sign\n",
    "xfreegarantee = np.array([0.0, 0.0]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bb81b5",
   "metadata": {},
   "source": [
    "## Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_collision(x):\n",
    "    R_OBS = 0.8\n",
    "    return np.linalg.norm(x, axis=1) <= R_OBS\n",
    "\n",
    "\n",
    "N_TRAIN = 600\n",
    "dof = 2\n",
    "X_train = np.random.uniform(-np.pi, np.pi, size=(N_TRAIN, dof))\n",
    "# y_train = np.where(is_collision(X_train), -1, +1)\n",
    "y_train = np.where(is_collision(X_train), +1, -1)\n",
    "xfreegarantee = np.array([1, 1]).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be9445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "sigma = 0.5\n",
    "K = rbf_kernel(X_train, X_train, gamma=1 / (2 * sigma**2))\n",
    "\n",
    "alpha = np.zeros(N_TRAIN)\n",
    "\n",
    "# simple online perceptron\n",
    "epochs = 100\n",
    "for _ in range(epochs):  # few epochs is enough\n",
    "    for i in range(N_TRAIN):\n",
    "        f_i = np.sum(alpha * y_train * K[:, i])\n",
    "        if y_train[i] * f_i <= 0:\n",
    "            alpha[i] += 1\n",
    "\n",
    "\n",
    "def f_hat(X):\n",
    "    Kx = rbf_kernel(X, X_train, gamma=1 / (2 * sigma**2))\n",
    "    return Kx @ (alpha * y_train)\n",
    "\n",
    "\n",
    "# check sign to flip the label for non-covex space application\n",
    "if f_hat(xfreegarantee)[0] < 0:\n",
    "    alpha *= -1\n",
    "\n",
    "xges1 = np.array([[0.0, 0.0]])\n",
    "xges2 = np.array([[1.0, 1.0]])\n",
    "fges1 = f_hat(xges1)\n",
    "print(\"f_hat at x = 0:\", fges1)\n",
    "fges2 = f_hat(xges2)\n",
    "print(\"f_hat at x = 1:\", fges2)\n",
    "\n",
    "grid = 200\n",
    "xs = np.linspace(-np.pi, np.pi, grid)\n",
    "ys = np.linspace(-np.pi, np.pi, grid)\n",
    "XX, YY = np.meshgrid(xs, ys)\n",
    "XY = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = f_hat(XY).reshape(grid, grid)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\")\n",
    "plt.contour(XX, YY, Z, levels=[0], colors=\"black\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Learned free-space scalar field f̂(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa39e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_adjacency(X, f, sigma=0.6):\n",
    "    W = rbf_kernel(X, X, gamma=1 / (2 * sigma**2))\n",
    "    conf = 1 / (1 + np.exp(-f))  # sigmoid\n",
    "    W *= np.minimum(conf[:, None], conf[None, :])\n",
    "    np.fill_diagonal(W, 0)\n",
    "    return W\n",
    "\n",
    "                                                                                                                                           \n",
    "def soft_adjacency_mid_penalty(X, f, sigma=0.6):\n",
    "    W = rbf_kernel(X, X, gamma=1 / (2 * sigma**2))\n",
    "    conf = 1 / (1 + np.exp(-f))  # sigmoid\n",
    "    W *= np.minimum(conf[:, None], conf[None, :])\n",
    "\n",
    "    # centers = (X_nodes[:, None, :] + X_nodes[None, :, :]) / 2\n",
    "    # midpoints_flat = centers.reshape(-1, 2)\n",
    "    # values = f_hat(midpoints_flat).reshape(len(X_nodes), len(X_nodes))\n",
    "    # p = 1 / (1 + np.exp(-values))\n",
    "    # W *= p\n",
    "    # must optimize later for memory efficiency\n",
    "    for i in range(len(X)):\n",
    "        for j in range(i + 1, len(X)):\n",
    "            m = 0.5 * (X[i] + X[j])\n",
    "            p = 1 / (1 + np.exp(-f_hat(m[None])[0]))\n",
    "            W[i, j] *= p\n",
    "            W[j, i] *= p\n",
    "\n",
    "    np.fill_diagonal(W, 0)\n",
    "    return W\n",
    "\n",
    "\n",
    "def soft_adjacency_local(X, f, sigma=0.6, k=15):\n",
    "    N = len(X)\n",
    "    W = np.zeros((N, N))\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=k + 1).fit(X)\n",
    "    distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "    conf = 1 / (1 + np.exp(-f))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j, d in zip(indices[i][1:], distances[i][1:]):\n",
    "            w = np.exp(-(d**2) / (2 * sigma**2))\n",
    "            w *= np.minimum(conf[i], conf[j])\n",
    "            W[i, j] = W[j, i] = w\n",
    "\n",
    "    return W\n",
    "\n",
    "\n",
    "def soft_adjacency_radius(X, f, sigma=0.6, r_conn=0.6):\n",
    "    N = len(X)\n",
    "    W = np.zeros((N, N))\n",
    "\n",
    "    nbrs = NearestNeighbors(radius=r_conn).fit(X)\n",
    "    indices = nbrs.radius_neighbors(X, return_distance=False)\n",
    "\n",
    "    conf = 1 / (1 + np.exp(-f))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in indices[i]:\n",
    "            if j == i:\n",
    "                continue\n",
    "            d = np.linalg.norm(X[i] - X[j])\n",
    "            w = np.exp(-(d**2) / (2 * sigma**2))\n",
    "            w *= min(conf[i], conf[j])\n",
    "            W[i, j] = w\n",
    "            W[j, i] = w\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e77158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_NODES = 200\n",
    "X_nodes = np.random.uniform(-np.pi, np.pi, size=(N_NODES, 2))\n",
    "f_nodes = f_hat(X_nodes)\n",
    "\n",
    "# confidence threshold filter\n",
    "tau = 0.5\n",
    "mask = f_nodes > tau\n",
    "X_nodes = X_nodes[mask]\n",
    "f_nodes = f_nodes[mask]\n",
    "\n",
    "# W = soft_adjacency(X_nodes, f_nodes)\n",
    "W = soft_adjacency_mid_penalty(X_nodes, f_nodes)\n",
    "print(f\"Shape of W of sample free node before start-goal {W.shape}\")\n",
    "# W = soft_adjacency_local(X_nodes, f_nodes, k=15)\n",
    "# W = soft_adjacency_radius(X_nodes, f_nodes, r_conn=0.2)\n",
    "\n",
    "# estimate shortest path from start to goal\n",
    "start = np.array([-2.5, -2.5])\n",
    "goal = np.array([2.5, 2.5])\n",
    "X_all = np.vstack([start, goal, X_nodes])\n",
    "f_all = np.concatenate([f_hat(start[None])[0:1], f_hat(goal[None])[0:1], f_nodes])\n",
    "# W_all = soft_adjacency(X_all, f_all)\n",
    "W_all = soft_adjacency_mid_penalty(X_all, f_all)\n",
    "print(f\"Shape of W of all nodes with start-goal {W_all.shape}\")\n",
    "C = 1 / (W_all + 1e-6)  # convert similarity → cost\n",
    "\n",
    "# debug\n",
    "print(f\"W_all\", W_all)\n",
    "print(f\"C\", C)\n",
    "\n",
    "dist, pred = shortest_path(C, return_predecessors=True)\n",
    "path = []\n",
    "j = 1  # goal index\n",
    "while j != -9999:\n",
    "    path.append(j)\n",
    "    j = pred[0, j]\n",
    "path = path[::-1]\n",
    "\n",
    "pathlength = 0.0\n",
    "for i in range(len(path) - 1):\n",
    "    pathlength += np.linalg.norm(X_all[path[i + 1]] - X_all[path[i]])\n",
    "print(f\"Path length: {pathlength:.2f}\")\n",
    "\n",
    "path_xy = X_all[path]\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\", alpha=0.4)\n",
    "theta = np.linspace(0, 2 * np.pi, 200)\n",
    "# plt.plot(R_OBS * np.cos(theta), R_OBS * np.sin(theta), \"k\")\n",
    "plt.scatter(X_nodes[:, 0], X_nodes[:, 1], s=5, c=\"blue\")\n",
    "plt.plot(path_xy[:, 0], path_xy[:, 1], \"k-\", linewidth=2)\n",
    "plt.scatter(*start, c=\"green\", s=80)\n",
    "plt.scatter(*goal, c=\"red\", s=80)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Path via learned free-space connectivity (no collision checks)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945fdaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate shortest path from start to goal\n",
    "import time\n",
    "q1 = np.array([-1.0, 2.5])\n",
    "q2 = np.array([1.0, 2.5])\n",
    "q3 = np.array([0.15, 0.60])\n",
    "q4 = np.array([2.5, 1.5])\n",
    "q5 = np.array([-2.5, -1.5])\n",
    "q6 = np.array([2.40, -0.4])\n",
    "q7 = np.array([-2.0, 2.5])\n",
    "q8 = np.array([1.0, -2.0])\n",
    "q9 = np.array([-3.0, 0.0])\n",
    "q10 = np.array([-3.0, 2.5])\n",
    "# sgpairs = {\n",
    "#     0: (np.array([-3.0, 0.0]), np.array([-3.0, 2.5])),\n",
    "#     1: (np.array([0.0, 2.0]), np.array([2.5, -2.5])),\n",
    "#     2: (np.array([0.0, 2.0]), np.array([0.0, -2.5])),\n",
    "# }\n",
    "sgpairs = {\n",
    "    0: (q1, q2),\n",
    "    1: (q3, q4),\n",
    "    2: (q5, q6),\n",
    "    3: (q7, q8),\n",
    "    4: (q9, q10),\n",
    "}\n",
    "\n",
    "pathsave = {x: [] for x in sgpairs}\n",
    "pathlengthsave = {x: 0.0 for x in sgpairs}\n",
    "X_allsave = {x: None for x in sgpairs}\n",
    "\n",
    "for key in sgpairs:\n",
    "    p1s = time.time()\n",
    "    start, goal = sgpairs[key]\n",
    "    print(f\"Processing start-goal pair {key}: start={start}, goal={goal}\")\n",
    "    X_all = np.vstack([start, goal, X_nodes])\n",
    "    X_allsave[key] = X_all\n",
    "    f_all = np.concatenate(\n",
    "        [f_hat(start[None])[0:1], f_hat(goal[None])[0:1], f_nodes]\n",
    "    )\n",
    "    W_all = soft_adjacency_mid_penalty(X_all, f_all)\n",
    "    C = 1 / (W_all + 1e-6)  # convert similarity → cost\n",
    "    p1e = time.time()\n",
    "    print(f\"  Adjacency matrix computation time: {p1e - p1s:.2f} s\")\n",
    "\n",
    "    # save for debugging\n",
    "    # savep = os.path.join(rsrc, f\"W_all_{key}.txt\")\n",
    "    # np.savetxt(savep, W_all, delimiter=\",\", fmt=\"%.2f\")\n",
    "\n",
    "    p2s = time.time()\n",
    "    dist, pred = shortest_path(C, return_predecessors=True)\n",
    "    path = []\n",
    "    j = 1  # goal index\n",
    "    while j != -9999:\n",
    "        path.append(j)\n",
    "        j = pred[0, j]\n",
    "    path = path[::-1]\n",
    "    pathsave[key] = path\n",
    "    p2e = time.time()\n",
    "    print(f\"  Shortest path computation time: {p2e - p2s:.2f} s\")\n",
    "\n",
    "    pathlength = 0.0\n",
    "    for i in range(len(path) - 1):\n",
    "        pathlength += np.linalg.norm(X_all[path[i + 1]] - X_all[path[i]])\n",
    "    pathlengthsave[key] = pathlength\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(30, 6))\n",
    "for key in sgpairs:\n",
    "    path_xy = X_allsave[key][pathsave[key]]\n",
    "    start, goal = sgpairs[key]\n",
    "    axes[key].set_title(\n",
    "        f\"Est.Path {key} length: {pathlengthsave[key]:.2f}\", fontsize=14\n",
    "    )\n",
    "    axes[key].contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\", alpha=0.4)\n",
    "    axes[key].scatter(X_nodes[:, 0], X_nodes[:, 1], s=6, c=\"blue\")\n",
    "    axes[key].plot(path_xy[:, 0], path_xy[:, 1], \"k-\", linewidth=2)\n",
    "    axes[key].scatter(*start, c=\"green\", s=80)\n",
    "    axes[key].scatter(*goal, c=\"red\", s=80)\n",
    "    axes[key].set_aspect(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sigma = 0.5\n",
    "model = SVC(kernel=\"rbf\", gamma=1 / (2 * sigma**2), C=1.0)\n",
    "ynnn_train = np.where(y_train == -1, 1, -1)\n",
    "\n",
    "model.fit(X_train, ynnn_train)\n",
    "fhater = model.decision_function\n",
    "# N = 10000000, 6dof trained in 3min on laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b651ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dof = 2\n",
    "xges = np.array([[0.0] * dof])\n",
    "xges2 = np.array([[1.0] * dof])\n",
    "y_pred = model.predict(xges)\n",
    "y_pred2 = model.predict(xges2)\n",
    "fges = fhater(xges)\n",
    "fges2 = fhater(xges2)\n",
    "print(\"SVM prediction at xges (0s):\", y_pred)\n",
    "print(\"SVM prediction at xges2 (1s):\", y_pred2)\n",
    "print(\"SVM decision function at xges (0s):\", fges)\n",
    "print(\"SVM decision function at xges2 (1s):\", fges2)\n",
    "\n",
    "xt = np.array([[0, 0]])\n",
    "ft = fhater(xt)\n",
    "print(\"SVM decision function at test point (0,0):\", ft)\n",
    "xtdelta = np.array([[0.1, 0.1]])\n",
    "ftdelta = fhater(xtdelta)\n",
    "print(\"SVM decision function at test point (0.1, 0.1):\", ftdelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "supvecs = model.support_vectors_\n",
    "supvecs_labels = y_train[model.support_]\n",
    "supvecs_free = supvecs[supvecs_labels == +1]\n",
    "supvecs_cols = supvecs[supvecs_labels == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ed20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_adjacency_mid_penalty(X, f, sigma=0.6):\n",
    "    W = rbf_kernel(X, X, gamma=1 / (2 * sigma**2))\n",
    "    conf = 1 / (1 + np.exp(-f))  # sigmoid\n",
    "    W *= np.minimum(conf[:, None], conf[None, :])\n",
    "\n",
    "    # centers = (X_nodes[:, None, :] + X_nodes[None, :, :]) / 2\n",
    "    # midpoints_flat = centers.reshape(-1, 2)\n",
    "    # values = f_hat(midpoints_flat).reshape(len(X_nodes), len(X_nodes))\n",
    "    # p = 1 / (1 + np.exp(-values))\n",
    "    # W *= p\n",
    "    # must optimize later for memory efficiency\n",
    "    for i in range(len(X)):\n",
    "        for j in range(i + 1, len(X)):\n",
    "            m = 0.5 * (X[i] + X[j])\n",
    "            p = 1 / (1 + np.exp(-fhater(m[None])[0]))\n",
    "            W[i, j] *= p\n",
    "            W[j, i] *= p\n",
    "\n",
    "    np.fill_diagonal(W, 0)\n",
    "    return W\n",
    "\n",
    "\n",
    "N_NODES = 200\n",
    "X_nodes = np.random.uniform(-np.pi, np.pi, size=(N_NODES, 2))\n",
    "X_nodes = supvecs_free\n",
    "# X_nodes = supvecs_cols\n",
    "f_nodes = fhater(X_nodes)\n",
    "\n",
    "# confidence threshold filter\n",
    "# tau = 0.5\n",
    "# mask = f_nodes > tau\n",
    "# X_nodes = X_nodes[mask]\n",
    "# f_nodes = f_nodes[mask]\n",
    "\n",
    "\n",
    "# estimate shortest path from start to goal\n",
    "start = np.array([-2.5, -2.5])\n",
    "goal = np.array([2.5, 2.5])\n",
    "X_all = np.vstack([start, goal, X_nodes])\n",
    "f_all = np.concatenate([fhater(start[None])[0:1], fhater(goal[None])[0:1], f_nodes])\n",
    "# W_all = soft_adjacency(X_all, f_all)\n",
    "W_all = soft_adjacency_mid_penalty(X_all, f_all)\n",
    "print(f\"Shape of W of all nodes with start-goal {W_all.shape}\")\n",
    "C = 1 / (W_all + 1e-6)  # convert similarity → cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b036da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist, pred = shortest_path(C, return_predecessors=True)\n",
    "path = []\n",
    "j = 1  # goal index\n",
    "while j != -9999:\n",
    "    path.append(j)\n",
    "    j = pred[0, j]\n",
    "path = path[::-1]\n",
    "\n",
    "pathlength = 0.0\n",
    "for i in range(len(path) - 1):\n",
    "    pathlength += np.linalg.norm(X_all[path[i + 1]] - X_all[path[i]])\n",
    "print(f\"Path length: {pathlength:.2f}\")\n",
    "\n",
    "pathq = X_all[path]\n",
    "print(f\"Path indices: {path}\")\n",
    "print(f\"Path length: {pathlength:.2f}\")\n",
    "print(f\"Path configurations:\\n{pathq}\")\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\", alpha=0.4)\n",
    "plt.scatter(X_nodes[:, 0], X_nodes[:, 1], s=5, c=\"blue\")\n",
    "plt.plot(pathq[:, 0], pathq[:, 1], \"k-\", linewidth=2)\n",
    "plt.scatter(*start, c=\"green\", s=80)\n",
    "plt.scatter(*goal, c=\"red\", s=80)\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Path via learned free-space connectivity (no collision checks)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 200\n",
    "xs = np.linspace(-np.pi, np.pi, grid)\n",
    "ys = np.linspace(-np.pi, np.pi, grid)\n",
    "XX, YY = np.meshgrid(xs, ys)\n",
    "XY = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = model.predict(XY).reshape(grid, grid)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\")\n",
    "plt.contour(XX, YY, Z, levels=[0], colors=\"black\")\n",
    "plt.plot(\n",
    "    supvecs_free[:, 0],\n",
    "    supvecs_free[:, 1],\n",
    "    \"ro\",\n",
    "    markersize=5,\n",
    "    label=\"Support Vectors (+1)\",\n",
    ")\n",
    "plt.plot(\n",
    "    supvecs_cols[:, 0],\n",
    "    supvecs_cols[:, 1],\n",
    "    \"bo\",\n",
    "    markersize=5,\n",
    "    label=\"Support Vectors (-1)\",\n",
    ")\n",
    "# plt.plot(sup_vecs[:, 0], sup_vecs[:, 1], \"ko\", markersize=3, label=\"Support Vectors\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Learned free-space scalar field f̂(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 200\n",
    "xs = np.linspace(-np.pi, np.pi, grid)\n",
    "ys = np.linspace(-np.pi, np.pi, grid)\n",
    "XX, YY = np.meshgrid(xs, ys)\n",
    "XY = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = fhater(XY).reshape(grid, grid)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\")\n",
    "plt.contour(XX, YY, Z, levels=[0], colors=\"black\")\n",
    "plt.plot(\n",
    "    supvecs_free[:, 0],\n",
    "    supvecs_free[:, 1],\n",
    "    \"ro\",\n",
    "    markersize=5,\n",
    "    label=\"Support Vectors (+1)\",\n",
    ")\n",
    "plt.plot(\n",
    "    supvecs_cols[:, 0],\n",
    "    supvecs_cols[:, 1],\n",
    "    \"bo\",\n",
    "    markersize=5,\n",
    "    label=\"Support Vectors (-1)\",\n",
    ")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Learned free-space scalar field f̂(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54ccc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.array([-1.0, 2.5])\n",
    "q2 = np.array([1.0, 2.5])\n",
    "q3 = np.array([0.15, 0.60])\n",
    "q4 = np.array([2.5, 1.5])\n",
    "q5 = np.array([-2.5, -1.5])\n",
    "q6 = np.array([2.40, -0.4])\n",
    "q7 = np.array([-2.0, 2.5])\n",
    "q8 = np.array([1.0, -2.0])\n",
    "q9 = np.array([-3.0, 0.0])\n",
    "q10 = np.array([-3.0, 2.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af948aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = np.linspace(q1, q2, 10)\n",
    "fp = fhater(pp)\n",
    "print(\"SVM decision function along line from q1 to q2:\", fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c99bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = 200\n",
    "xs = np.linspace(-np.pi, np.pi, grid)\n",
    "ys = np.linspace(-np.pi, np.pi, grid)\n",
    "XX, YY = np.meshgrid(xs, ys)\n",
    "XY = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = fhater(XY).reshape(grid, grid)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot([q1[0], q2[0]], [q1[1], q2[1]], 'k-', linewidth=2)\n",
    "plt.plot(pp[:,0], pp[:,1], 'ro--')\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\")\n",
    "plt.contour(XX, YY, Z, levels=[0], colors=\"black\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Learned free-space scalar field f̂(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3bfeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(signal, realmin, realmax):\n",
    "    sigmin = np.min(signal)\n",
    "    sigmax = np.max(signal)\n",
    "    scaled = (signal - sigmin) / (sigmax - sigmin)\n",
    "    mapped = realmin + scaled * (realmax - realmin)\n",
    "    return mapped\n",
    "\n",
    "\n",
    "grid = 200\n",
    "xs = np.linspace(-np.pi, np.pi, grid)\n",
    "ys = np.linspace(-np.pi, np.pi, grid)\n",
    "XX, YY = np.meshgrid(xs, ys)\n",
    "XY = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "Z = fhater(XY).reshape(grid, grid)\n",
    "Z = 1 / (1 + np.exp(-Z))  # sigmoid\n",
    "Z = mapping(Z, -1, 1)\n",
    "print(np.max(Z), np.min(Z))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot([q1[0], q2[0]], [q1[1], q2[1]], \"k-\", linewidth=2)\n",
    "plt.plot(pp[:, 0], pp[:, 1], \"ro--\")\n",
    "plt.contourf(XX, YY, Z, levels=50, cmap=\"coolwarm\")\n",
    "plt.contour(XX, YY, Z, levels=[0], colors=\"black\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.title(\"Learned free-space scalar field f̂(x)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robotics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
